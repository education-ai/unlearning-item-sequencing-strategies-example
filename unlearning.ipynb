{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ad9456e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Generate Learning Content for Language Teaching Materials\n",
    "Prototype for Experiments, work-in-progress with limited comments\n",
    "\"\"\"\n",
    "__author__ = [\"Leo S. R端dian\"]\n",
    "__copyright__ = \"2024, R端dian\"\n",
    "__credits__ = [\"Leo S. R端dian\"]\n",
    "__license__ = \"CC BY-NC-SA\"\n",
    "__version__ = \"1.0.0\"\n",
    "__maintainer__ = [\"Leo S. R端dian\"]\n",
    "__email__ =[\"ruediasy@informatik.hu-berlin.de\"]\n",
    "__status__ = \"Work-in-Progress\"\n",
    "\n",
    "import json\n",
    "from tensorflow import keras\n",
    "from keras.models import load_model, Model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.layers import LSTM, Bidirectional, Input, Flatten, Dropout, Dense\n",
    "#from keras.layers import Dense\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import numpy as np\n",
    "from numpy import argmax\n",
    "\n",
    "filename1 = \"model/sim/model1.hdf5\" # model1\n",
    "filename2 = \"model/sim/model2.hdf5\" # model2\n",
    "weight = [.7,.3] # weight to soft-merge model 1 and 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a00a91d",
   "metadata": {},
   "source": [
    "# Helper Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a9c4ac56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8130, 15)\n"
     ]
    }
   ],
   "source": [
    "# define mappings, functions, and cache\n",
    "\n",
    "with open('newsequences-mesh.json', 'r') as f:\n",
    "    course = json.load(f)\n",
    "    \n",
    "methods_list = ['introduction', 'memorization-challenge', '#motivation', 'translation-challenge', 'translation-correction', '#dashboard', 'listening-correction', 'writing', 'end', 'translation', 'listening', 'memorization', 'listening-challenge', 'flashcard', 'memorization-correction']\n",
    "\n",
    "def convert_to_hotvector(X,a):\n",
    "    mapping = {}\n",
    "    for x in range(len(a)):\n",
    "      mapping[a[x]] = x\n",
    "   \n",
    "    # integer representation\n",
    "    for x in range(len(X)):\n",
    "      X[x] = mapping[X[x]]\n",
    "    \n",
    "    for x in range(len(a)):\n",
    "        X.append(x)\n",
    "        \n",
    "    C = to_categorical(X, num_classes=len(a))\n",
    "    C = C[:-(len(a))]\n",
    "    return C,mapping\n",
    "\n",
    "def getVector(s1,s2,s3,s4,s5):\n",
    "    global a,b,c,d,e\n",
    "    global mapA,mapB,mapC,mapD,mapE\n",
    "    \n",
    "    A_c,mapA = convert_to_hotvector(list(s1),a) \n",
    "    B_c,mapB = convert_to_hotvector(list(s2),b) \n",
    "    C_c,mapC = convert_to_hotvector(list(s3),c)\n",
    "    D_c,mapD = convert_to_hotvector(list(s4),d) \n",
    "    E_c,mapE = convert_to_hotvector(list(s5),e) \n",
    "    \n",
    "    return [A_c,B_c,C_c,D_c]\n",
    "\n",
    "def getVectorY(s1,s2,s3,s4,s5):\n",
    "    global a,b,c,d,e\n",
    "    global mapA,mapB,mapC,mapD,mapE\n",
    "    A_c,mapA = convert_to_hotvector(list(s1),a) \n",
    "    B_c,mapB = convert_to_hotvector(list(s2),b) \n",
    "    C_c,mapC = convert_to_hotvector(list(s3),c)\n",
    "    D_c,mapD = convert_to_hotvector(list(s4),d) \n",
    "    E_c,mapE = convert_to_hotvector(list(s5),e) \n",
    "    \n",
    "    A_c2 = np.zeros((B_c.shape[0],B_c.shape[1])) # override by 0 \n",
    "    C_c = np.zeros((B_c.shape[0],B_c.shape[1])) # override by 0 \n",
    "    E_c = np.zeros((B_c.shape[0],B_c.shape[1])) # override by 0 \n",
    "    \n",
    "    for i in range(len(A_c)):\n",
    "        for j in range(len(A_c[0])):\n",
    "            A_c2[i][j] = A_c[i][j]\n",
    "            \n",
    "    vec = []\n",
    "    for l in range(len(A_c)):\n",
    "        vec.append([A_c[l],B_c[l]])\n",
    "    return vec\n",
    "\n",
    "# prepare the dataset of input to output pairs encoded as integers\n",
    "seq_length = 2\n",
    "dataX = []\n",
    "dataXa = []\n",
    "dataXb = []\n",
    "dataXc = []\n",
    "dataXd=[]\n",
    "dataY = []\n",
    "\n",
    "trainCategoryY = []\n",
    "trainColorY = []\n",
    "dataX_test, dataY_test = [], []\n",
    "ytrain_1 = []\n",
    "ytrain_2 = []\n",
    "\n",
    "dataX_personality = []\n",
    "dataX_usermodel = []\n",
    "dataX_method = []\n",
    "\n",
    "cache = {}\n",
    "for i in course:\n",
    "    personality = i[0]\n",
    "    content = i[1]\n",
    "    for item in content:\n",
    "        method = item[0]\n",
    "        usermodel = item[1]\n",
    "        cachetest = ''.join(str(x) for x in personality)+''.join(str(x) for x in usermodel)+method\n",
    "        if not cachetest in cache:\n",
    "            dataX_personality.append(personality)\n",
    "            dataX_usermodel.append(usermodel)\n",
    "            dataX_method.append(method)\n",
    "            cache[cachetest]=1\n",
    "\n",
    "dataX_method,dataX_method_map = convert_to_hotvector(list(dataX_method),methods_list) \n",
    "\n",
    "# prepare Y\n",
    "all_dataY_method = []\n",
    "all_dataX_method = []\n",
    "all_dataX_personality = []\n",
    "all_dataX_usermodel = []\n",
    "\n",
    "for j in range(len(dataX_method)-1):\n",
    "    all_dataX_personality.append(dataX_personality[j])\n",
    "    all_dataX_usermodel.append(dataX_usermodel[j])\n",
    "    all_dataX_method.append(dataX_method[j])\n",
    "    all_dataY_method.append(dataX_method[j+1])\n",
    "   \n",
    "\n",
    "n_patterns = len(all_dataX_method)\n",
    "X_method = np.reshape(all_dataX_method, (n_patterns, (len(methods_list)), 1))\n",
    "Y_method = np.reshape(all_dataY_method, (n_patterns, (len(methods_list))))\n",
    "X_personality = np.reshape(all_dataX_personality, (n_patterns, 3, 1))\n",
    "X_usermodel = np.reshape(all_dataX_usermodel, (n_patterns, 4, 1))\n",
    "\n",
    "print(Y_method.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c910b40",
   "metadata": {},
   "source": [
    "# Define the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "621d6c36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " Input_method (InputLayer)      [(None, 15, 1)]      0           []                               \n",
      "                                                                                                  \n",
      " Input_usermodel (InputLayer)   [(None, 4, 1)]       0           []                               \n",
      "                                                                                                  \n",
      " Input_personality (InputLayer)  [(None, 3, 1)]      0           []                               \n",
      "                                                                                                  \n",
      " LSTM_method (Bidirectional)    (None, 32)           2304        ['Input_method[0][0]']           \n",
      "                                                                                                  \n",
      " flatten_2 (Flatten)            (None, 4)            0           ['Input_usermodel[0][0]']        \n",
      "                                                                                                  \n",
      " flatten_3 (Flatten)            (None, 3)            0           ['Input_personality[0][0]']      \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 39)           0           ['LSTM_method[0][0]',            \n",
      "                                                                  'flatten_2[0][0]',              \n",
      "                                                                  'flatten_3[0][0]']              \n",
      "                                                                                                  \n",
      " Dropout (Dropout)              (None, 39)           0           ['concatenate_1[0][0]']          \n",
      "                                                                                                  \n",
      " output_method (Dense)          (None, 15)           600         ['Dropout[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 2,904\n",
      "Trainable params: 2,904\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def make_model():\n",
    "    input_method=Input(shape=(X_method.shape[1], X_method.shape[2]), name=\"Input_method\")\n",
    "    input_usermodel=Input(shape=(X_usermodel.shape[1], X_usermodel.shape[2]), name=\"Input_usermodel\")\n",
    "    input_personality=Input(shape=(X_personality.shape[1], X_personality.shape[2]), name=\"Input_personality\")\n",
    "    \n",
    "    bi_lstm_method = Bidirectional(LSTM(16,return_sequences=False), name=\"LSTM_method\")(input_method)\n",
    "    \n",
    "    f_usermodel = Flatten()(input_usermodel)\n",
    "    f_personality = Flatten()(input_personality)\n",
    "    \n",
    "    all_input = keras.layers.concatenate([bi_lstm_method, f_usermodel, f_personality]) #\n",
    "        \n",
    "    dropout1 = Dropout(0.4, name=\"Dropout\")(all_input)\n",
    "\n",
    "    output_a = Dense(15, activation='softmax', name='output_method')(dropout1)  \n",
    "    \n",
    "    model = Model(inputs = [input_method,input_usermodel,input_personality], outputs=[output_a]) # \n",
    " \n",
    "    return model\n",
    "\n",
    "model = make_model()\n",
    "\n",
    "losses ={'output_method':keras.losses.CategoricalCrossentropy()} \n",
    "optimizers = keras.optimizers.Adam(clipnorm=1)\n",
    "\n",
    "model.compile(optimizer=optimizers, loss=losses,metrics=\"accuracy\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "950d6cad",
   "metadata": {},
   "source": [
    "# Soft-Merge Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1250cb77",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = load_model(filename1, compile=False) \n",
    "weights_1 = model1.get_weights()\n",
    "\n",
    "model2 = load_model(filename2, compile=False) \n",
    "weights_2 = model2.get_weights()\n",
    "\n",
    "weights_merge  = np.average( np.array([ weights_1, weights_2]), axis=0 , weights=weight)\n",
    "\n",
    "model.set_weights(weights_merge)\n",
    "model.save('model/sim/merge.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38295b34",
   "metadata": {},
   "source": [
    "# Evaluation \"Amplifying/Unlearning\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca6c5342",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('newsequences-test-cv.json', 'r') as f:\n",
    "    course_test = json.load(f)\n",
    "\n",
    "testdataX_personality = []\n",
    "testdataX_usermodel = []\n",
    "testdataX_method = []\n",
    "\n",
    "for i in course_test:\n",
    "    personality = i[0]\n",
    "    content = i[1]\n",
    "    for item in content:\n",
    "        method = item[0]\n",
    "        usermodel = item[1]\n",
    "        testdataX_personality.append(personality)\n",
    "        testdataX_usermodel.append(usermodel)\n",
    "        testdataX_method.append(method)\n",
    "\n",
    "testdataX_method,testdataX_method_map = convert_to_hotvector(list(testdataX_method),methods_list) \n",
    "testdataX_method_map_reverse = {}\n",
    "for i,val in testdataX_method_map.items():\n",
    "    testdataX_method_map_reverse[val]=i\n",
    "\n",
    "# prepare Y\n",
    "testall_dataY_method = []\n",
    "testall_dataX_method = []\n",
    "testall_dataX_personality = []\n",
    "testall_dataX_usermodel = []\n",
    "\n",
    "for j in range(len(testdataX_method)-1):\n",
    "    testall_dataX_personality.append(testdataX_personality[j])\n",
    "    testall_dataX_usermodel.append(testdataX_usermodel[j])\n",
    "    testall_dataX_method.append(testdataX_method[j])\n",
    "    testall_dataY_method.append(testdataX_method[j+1])\n",
    "\n",
    "def getprediction(pattern):\n",
    "        \n",
    "    n_patterns = 1\n",
    "    \n",
    "    X_method = np.reshape(pattern[0], (n_patterns, (len(methods_list)), 1))\n",
    "    X_personality = np.reshape(pattern[2], (n_patterns, 3, 1))\n",
    "    X_usermodel = np.reshape(pattern[1], (n_patterns, 4, 1))\n",
    "    \n",
    "    prediction = model.predict([X_method,X_usermodel,X_personality], verbose=0)\n",
    "    # make one-hot encoding\n",
    "    result = prediction\n",
    "    r_a = list(result[0])    \n",
    "    max_a = argmax(r_a)\n",
    "    r_a =  np.zeros((len(methods_list),), dtype=int)\n",
    "    r_a[max_a] = 1\n",
    "    \n",
    "    return r_a\n",
    "\n",
    "def testmeshing(pattern,current_method,predicted):\n",
    "    personality = pattern[2]\n",
    "    hit, nhit = 0, 0\n",
    "    \n",
    "    if predicted != 'end' and current_method != 'end':\n",
    "        if personality[0]==1: # correction\n",
    "            if predicted != 'writing' and predicted != 'introduction':# and cnt>4:\n",
    "                if current_method in ['sentenceconstruct','writing']:\n",
    "                    if '-correction' in predicted: hit += 1\n",
    "                    else: nhit += 1\n",
    "\n",
    "        if personality[2]==1: # challenge\n",
    "            if predicted != 'writing' and predicted != 'introduction' and not 'correction' in predicted:\n",
    "                if '-challenge' in predicted: hit += 1\n",
    "                else: nhit += 1\n",
    "        \n",
    "        if personality[1]==1 and current_method != '#dashboard' and current_method != 'introduction' and current_method != 'flashcard' and current_method != '#motivation'and predicted != 'writing': # gamification\n",
    "            if predicted == '#dashboard' or predicted == '#motivation':\n",
    "                hit += 1\n",
    "            else: nhit += 1\n",
    "        \n",
    "    if hit > 1: hit = 1\n",
    "    if nhit > 1: nhit = 1\n",
    "    \n",
    "    if hit == 1: nhit = 0\n",
    "    \n",
    "    return hit, nhit\n",
    "    \n",
    "def testantimeshing(pattern,current_method,predicted):\n",
    "    personality = pattern[2]    \n",
    "    hit, nhit = 0, 0\n",
    "    \n",
    "    if predicted != 'end' and current_method != 'end':\n",
    "        if personality[0]==0: # correction\n",
    "            if predicted != 'writing' and predicted != 'introduction':# and cnt>4:\n",
    "                if current_method in ['sentenceconstruct','writing']:\n",
    "                    if '-correction' in predicted: hit += 1\n",
    "                    else: nhit += 1\n",
    "\n",
    "        if personality[2]==0: # challenge\n",
    "            if predicted != 'writing' and predicted != 'introduction' and not 'correction' in predicted:\n",
    "                if '-challenge' in predicted: hit += 1\n",
    "                else: nhit += 1\n",
    "        \n",
    "        if personality[1]==0 and current_method != '#dashboard' and current_method != 'introduction' and current_method != 'flashcard' and current_method != '#motivation'and predicted != 'writing': # gamification\n",
    "            if predicted == '#dashboard' or predicted == '#motivation':\n",
    "                hit += 1\n",
    "            else: nhit += 1\n",
    "        \n",
    "    if hit > 1: hit = 1\n",
    "    if nhit > 1: nhit = 1\n",
    "    \n",
    "    if hit == 1: nhit = 0\n",
    "    \n",
    "    return hit, nhit\n",
    "\n",
    "# use merged model\n",
    "filename = 'model/sim/merge.hdf5'\n",
    "model.load_weights(filename)\n",
    "model.compile(optimizer=optimizers, loss=losses,metrics=\"accuracy\")\n",
    "\n",
    "teststeps = 1000\n",
    "hit_all, nhit_all, anz = 0,0,0\n",
    "mesh_hit_all, mesh_nhit_all, mesh_anz = 0,0,0\n",
    "antimesh_hit_all, antimesh_nhit_all, antimesh_anz = 0,0,0\n",
    "\n",
    "\n",
    "for num in range(teststeps):\n",
    "    # get random element\n",
    "    start = np.random.randint(0, len(testall_dataX_method)-1)\n",
    "    usermodel = testall_dataX_usermodel[start]\n",
    "    personality = testall_dataX_personality[start]\n",
    "    pattern = np.array([testall_dataX_method[start],testall_dataX_usermodel[start],testall_dataX_personality[start]])\n",
    "    ziel = np.array(testall_dataY_method[start])\n",
    "    \n",
    "    current_method = testdataX_method_map_reverse[argmax(testall_dataX_method[start])]\n",
    "    \n",
    "    predicted = getprediction(pattern)\n",
    "    if argmax(ziel) == argmax(predicted):\n",
    "        hit_all += 1\n",
    "    else:\n",
    "        nhit_all += 1\n",
    "    anz += 1\n",
    "    \n",
    "    predicted_method = testdataX_method_map_reverse[argmax(predicted)]\n",
    "    \n",
    "    # evaluation\n",
    "    mesh_hit, mesh_nhit = testmeshing(pattern,current_method,predicted_method)\n",
    "    if mesh_hit + mesh_nhit > 0:\n",
    "        mesh_hit_all += mesh_hit\n",
    "        mesh_nhit_all += mesh_nhit\n",
    "        mesh_anz += 1\n",
    "        \n",
    "    antimesh_hit, antimesh_nhit = testantimeshing(pattern,current_method,predicted_method)\n",
    "    if antimesh_hit + antimesh_nhit > 0:\n",
    "        antimesh_hit_all += antimesh_hit\n",
    "        antimesh_nhit_all += antimesh_nhit\n",
    "        antimesh_anz += 1      \n",
    "    \n",
    "print('---- Evaluation after first merge -----')\n",
    "\n",
    "print('mesh:',mesh_hit_all, mesh_nhit_all)\n",
    "print('mesh:',round(mesh_hit_all/mesh_anz,4), mesh_anz, 'not considered:',(teststeps-mesh_anz)) \n",
    "\n",
    "print('antimesh:',antimesh_hit_all, antimesh_nhit_all)\n",
    "print('antimesh:',round(antimesh_hit_all/antimesh_anz,4), antimesh_anz, 'not considered:',(teststeps-antimesh_anz)) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
